# Default values for hava.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

setup:
  license_user: hava
  license_email: example@hava.io
  license: 

environment:
  # dns domain the end user will connect on to access hava, e.g. hava.io 
  # this is used for cors, to it needs to match
  domain: "example.com"
  # The subdomain that the app runs on, default is 'hava' which will set up the application on e.g. hava.hava.io if hava.io is set as the domain
  web_subdomain: "hava"
  # used to enable or disable ssl for the endpoints. If set to true, ingress needs to be configured with a valid ssl certificate
  ssl: "false"
  # This is used to add additional allowed sources for CORS, needs to be fully qualified domains including protocol and port. e.g. 'https://qa.hava.io:9700'
  # Format is a comma separated string "https://qa.hava.io:9700,https://dev.hava.io:9700"
  cors_hosts:
  # Set to true to enable cors validation
  cors_enabled: false
  # Sets the log level for hava, suported values: debug, info, warn, error
  log_level: info
  # Sets up an http proxy for Hava to use when connecting to cloud providers to access the public APIs
  proxy:
  # This block is for enabling auth0 for managing user credentials, please reach out to hava support on details on how to configure this
  auth0:
    enabled:
    host:
    id:
    connection:
    secret: "dummy"

# This block is for setting the image used by the Hava pods. Changing if a private container repository is needed
image:
  repository: hava/self-hosted
  tag: 2.5.1408
  pull_policy: IfNotPresent
  # Set this to use a secret to authenticate with a private container registry
  pull_secret_name:

# this block is used to configure the k8s service account
serviceaccount:
  # set to false to not create a service account
  enabled: true
  # annotations to add to the service account
  annotations: {}
  # additional labels to add to the service account
  lables: {}

# This block configures the web and api pods
web:
  # Number of pods to run in parallel 
  replicas: 1
  # Used for performance tuning of the web instance
  concurrency: 2
  threads: 5
  # AWS ALB defaults to 60, needs to be 60 + timeout value
  persistent_timeout: 75 
  # CPU and memory limits of the pods, increase to scale the pods vertically
  cpu: 500m
  memory: 2048M
  
  ingress:
    # enabled default ingress, set to false to configure different ingress, e.g. gloo or nginx
    enable: true
    # The type of ingress to use. For historic reasons, this defaults to AWS. Supported values: AWS, AZURE
    type: AWS
    # add cert ARN here if ssl is set to true in environment
    acm_cert_arn: ""

# This block configures the notify pods
websocket:
  # Number of pods to run in parallel 
  replicas: 1
  #CPU and memory limits of the pods, increase to scale the pods vertically
  cpu: 100m
  memory: 256M

# This block configures the import pods
import:
  # configuration for automatic synchronization of sources
  auto_sync:
    # Enables the scheduled synchronization
    enabled: true
    # Number of syncs to add to the job queue at once, lower number smooths out the sync schedule, high number causes more peaky load
    count: 30
    # How often to run the synchronization, default every 24 hours
    minutes: 1440
  # configuration for AWS CAR
  # Either configure with Role based access or IAM keys
  aws:
    # set to true to use role based access
    # the k8s service account needs to be connected to an AWS AMI Role with assumeRole rights
    use_sa_role: false
    # The account containing either the role or the user
    account_id: "example"
    # aws access key id for the user (if using a user)
    access_key: "example"
    # aws secret key for the user (if using a user)
    secret_key: "example"

# This block configues the scheduler pods
clock:
  # Number of pods to run in parallel, 1 is recommended
  replicas: 1
  # User for performance tuning
  concurrency: 2
  pool: 40
  # CPU and memory limits of the pod, increase to scale pods vertically
  cpu: 100m
  memory: 1024M

# This block configures the environment render pods
render:
  # where renders will be stored when completed, supported values: s3, azure-blob
  storage_type: s3
  # prefix added to path for files stored in storage location
  storage_prefix: ""
  # Configuration for storage of render outputs in S3
  aws:
    # set to true to use role based access
    # the k8s service account needs to be connected to an AWS AMI Role with assumeRole rights
    use_sa_role: false
    # name of the S3 bucket to store render outputs in
    bucket: "example"
    # region that the S3 bucket has been configured for
    region: "example"
    # aws access key id for the user with access to the S3 bucket (if using a user)
    access_key: "example"
    # aws secret key for the user with access to the S3 bucket (if using a user)
    secret_key: "example"
  # settings used when storage_type is set to azure
  azure:
    # name of storage account to store renders
    storage_account: ""
    # name of the blob container to store renders in
    blob_container: ""
    # secret access key used to access storage account
    access_key: ""


workers:
  # Number of pods to run in parallel, 2 is recommended for a basic deployment
  replicas: 2
  # used for performance tuning
  concurrency: 2
  pool: 40
  # CPU and memory limits of the pod, increase to scale pods vertically
  cpu: 1000m
  memory: 2048M 

database:
  # uri of the postgres server endpoint to connect to
  host: "example"
  # port of the postgress server to connect to
  port: 5432
  # username of the user Hava uses to authenticate to postgres
  user: "postgres"
  # password of the user Hava uses to authneticate to postgres
  password: "havahava"
  # name of the database 
  name: "hava"

email: 
  smtp:
    # Username for the user to authenticate with the smtp endpoint, leave blank to use anonymous
    user:
    # Password for the user to authenticate with the smtp endpoint, leave blank to use anonymous
    pass:
    # Port to connect to the smpt endpoint
    port: 25
    # The endpoint to connect to
    endpoint: "example.com"
    # The address hava will use to send emails to users
    from_address: "noreply@example.com"
    # The name hava will use to send emails to users
    from_name: "No Reply"
    # The HELO domain to send to the smtp gateway if required
    domain: ""

cache:
  ## set to false if hosting redis externally. e.g. memstore paas
  enabled: true
  storage_class: hava
  image:
    name: redis
    tag: 4.0-alpine

# persistent storage configuration
storage:
  ## if the chart will define storage classes or not
  enable: true
  ## type of persistent storage, supported values: AWS, azure-blob, local
  type: AWS

elasticsearch:
  ## set to false if hosting elasticsearch externally
  enabled: true
  # Number of nodes to run in the elasticsearch cluster, minimum of 3, odd number works best
  replicas: 3
  password: "example"
  # Image repository to download the elastic image from, change if using an internal container registry
  image: hava/elasticsearch
  # the tag of the image
  imageTag: 6.8-s3-backup-1.0.6
  esConfig:
    # sets the max size of imported documents
    elasticsearch.yml: |
      http.max_content_length: 500mb
  backup:
    # Change this to disable backups for the elasticsearch deployment
    enabled: true
    # name of the S3 bucket to store backup snapshots in
    bucket_name:
    # aws access key id for the iam user to use for accessing the S3 bucket
    access_key:
    # aw secret key for iam user to use to accessign the S3 bucket
    secret_key:
  # used for adding secrets to the internal elastic keystore
  keystore:
  # this is needed, don't change
  - secretName: elasticsearch-secrets # hardcoded because helm does not support dynamic values here
    items:
    - key: es-secret-access-key
      path: s3.client.default.access_key
    - key: es-secret-secret-key
      path: s3.client.default.secret_key
  # Resoruce limits for the elastic nodes, incrase to scale vertically
  resources:
    requests:
      cpu: "250m"
      memory: "1536M"
    limits:
      cpu: "500m"
      memory: "1536M"
  # Perstitent storage for the elastic cluster, change this to increase the storage of the cluster
  volumeClaimTemplate:
    storageClassName: hava
    resources:
      requests:
        storage: 200Gi

kibana:
  # Number of kibana nodes to run, defaults to 0, scale up if need to connect and run maintenance on the elastic cluster
  replicas: 0

encryption:
  ## used to encrypt values stored in the database
  iv: # openssl rand -hex 8
  key: # openssl rand -hex 48

  ## used to encrypt cookies
  web_key: # openssl rand -hex 48

aws:
  # Set to a comma delimited list of regions to support, i.e. us-west-1,us-west-2. If blank it will import all regions.
  regions:
  # Set to false if you don't allow govcloud data to be imported
  govcloud_enabled: false

azure:
  # set operating mode for hava in Azure. To run Hava in Azure US Government Cloud set this to 'azureusgovcloud'
  environment: azurecloud